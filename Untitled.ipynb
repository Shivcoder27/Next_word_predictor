{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d09e0411-2387-4d46-89a8-caf9f4d8616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraqs = \"\"\"CNN and LSTM:\n",
    "\n",
    "Q: What is the purpose of using CNN in this project?\n",
    "A: CNN is used for feature extraction from MRI brain images.\n",
    "\n",
    "Q: Why might you integrate LSTM with CNN?\n",
    "A: To capture temporal or sequential patterns if dealing with sequential MRI slices or time-series data.\n",
    "\n",
    "Q: What type of data is used in this project?\n",
    "A: MRI scans of the brain for tumor classification.\n",
    "\n",
    "Q: How do you preprocess images for CNN?\n",
    "A: Resize, normalize pixel values, and convert them into tensors.\n",
    "\n",
    "Q: What are the common output classes for brain tumor classification?\n",
    "A: Tumor types like glioma, meningioma, pituitary tumor, or no tumor.\n",
    "\n",
    "Q: Which loss function is suitable for this classification task?\n",
    "A: Categorical Crossentropy for multi-class classification.\n",
    "\n",
    "Q: What optimizer can be used for training the model?\n",
    "A: Adam optimizer is commonly used for its efficiency.\n",
    "\n",
    "Q: How do you avoid overfitting in the CNN-LSTM model?\n",
    "A: Use techniques like dropout, data augmentation, and regularization.\n",
    "\n",
    "Q: What is the input format for LSTM?\n",
    "A: A sequence of features (e.g., extracted from CNN layers).\n",
    "\n",
    "Q: Which metric is commonly used to evaluate the model's performance?\n",
    "A: Accuracy, precision, recall, and F1-score.\n",
    "\n",
    "Q: How do you handle class imbalance in the dataset?\n",
    "A: By using techniques like oversampling, undersampling, or class weights.\n",
    "\n",
    "Q: What is transfer learning, and why is it useful here?\n",
    "A: Reusing pre-trained CNN models like VGG16 to leverage learned features and reduce training time.\n",
    "\n",
    "Q: Can this model work for real-time detection?\n",
    "A: Yes, with optimizations, it can be adapted for real-time applications.\n",
    "\n",
    "Q: What activation function is used in the final layer for multi-class classification?\n",
    "A: Softmax activation function.\n",
    "\n",
    "Q: What is the role of batch normalization in CNN?\n",
    "A: It stabilizes and speeds up training by normalizing layer inputs.\n",
    "\n",
    "Q: What library can you use for implementing CNN and LSTM?\n",
    "A: Libraries like TensorFlow or PyTorch.\n",
    "\n",
    "Q: How do you split the dataset?\n",
    "A: Into training, validation, and testing sets, typically in a 70-15-15 ratio.\n",
    "\n",
    "Q: How do you visualize the model’s performance?\n",
    "A: Using confusion matrices, accuracy/loss plots, and ROC curves.\n",
    "\n",
    "Q: What data augmentation techniques are useful for this project?\n",
    "A: Rotation, flipping, zooming, and shifting.\n",
    "\n",
    "Q: How do you save the trained model?\n",
    "A: Save the model using .h5 or .pth format for future use.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b6358a-3fba-496c-841b-a19a93aa4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f5c591-6b14-4788-9b19-7294579c795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6a44b5e-2a97-483d-9196-2946790fe77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([fraqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bc5cbdd-9d01-44fd-8e95-8ac018222567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "719e7b89-90bc-4f73-9d52-be72b88d581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for sentence in fraqs.split('\\n'):\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for i in range(1,len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3707e13-e0cd-4223-973d-969f3f83c65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 5],\n",
       " [7, 5, 15],\n",
       " [2, 8],\n",
       " [2, 8, 6],\n",
       " [2, 8, 6, 4],\n",
       " [2, 8, 6, 4, 63],\n",
       " [2, 8, 6, 4, 63, 16],\n",
       " [2, 8, 6, 4, 63, 16, 22],\n",
       " [2, 8, 6, 4, 63, 16, 22, 7],\n",
       " [2, 8, 6, 4, 63, 16, 22, 7, 10],\n",
       " [2, 8, 6, 4, 63, 16, 22, 7, 10, 17],\n",
       " [2, 8, 6, 4, 63, 16, 22, 7, 10, 17, 28],\n",
       " [1, 7],\n",
       " [1, 7, 6],\n",
       " [1, 7, 6, 11],\n",
       " [1, 7, 6, 11, 3],\n",
       " [1, 7, 6, 11, 3, 64],\n",
       " [1, 7, 6, 11, 3, 64, 65],\n",
       " [1, 7, 6, 11, 3, 64, 65, 37],\n",
       " [1, 7, 6, 11, 3, 64, 65, 37, 29],\n",
       " [1, 7, 6, 11, 3, 64, 65, 37, 29, 30],\n",
       " [1, 7, 6, 11, 3, 64, 65, 37, 29, 30, 38],\n",
       " [2, 39],\n",
       " [2, 39, 66],\n",
       " [2, 39, 66, 9],\n",
       " [2, 39, 66, 9, 67],\n",
       " [2, 39, 66, 9, 67, 15],\n",
       " [2, 39, 66, 9, 67, 15, 31],\n",
       " [2, 39, 66, 9, 67, 15, 31, 7],\n",
       " [1, 32],\n",
       " [1, 32, 68],\n",
       " [1, 32, 68, 69],\n",
       " [1, 32, 68, 69, 12],\n",
       " [1, 32, 68, 69, 12, 40],\n",
       " [1, 32, 68, 69, 12, 40, 70],\n",
       " [1, 32, 68, 69, 12, 40, 70, 71],\n",
       " [1, 32, 68, 69, 12, 40, 70, 71, 72],\n",
       " [1, 32, 68, 69, 12, 40, 70, 71, 72, 31],\n",
       " [1, 32, 68, 69, 12, 40, 70, 71, 72, 31, 40],\n",
       " [1, 32, 68, 69, 12, 40, 70, 71, 72, 31, 40, 29],\n",
       " [1, 32, 68, 69, 12, 40, 70, 71, 72, 31, 40, 29, 73],\n",
       " [1, 32, 68, 69, 12, 40, 70, 71, 72, 31, 40, 29, 73, 12],\n",
       " [1, 32, 68, 69, 12, 40, 70, 71, 72, 31, 40, 29, 73, 12, 23],\n",
       " [1, 32, 68, 69, 12, 40, 70, 71, 72, 31, 40, 29, 73, 12, 23, 74],\n",
       " [1, 32, 68, 69, 12, 40, 70, 71, 72, 31, 40, 29, 73, 12, 23, 74, 24],\n",
       " [2, 8],\n",
       " [2, 8, 75],\n",
       " [2, 8, 75, 16],\n",
       " [2, 8, 75, 16, 24],\n",
       " [2, 8, 75, 16, 24, 6],\n",
       " [2, 8, 75, 16, 24, 6, 11],\n",
       " [2, 8, 75, 16, 24, 6, 11, 10],\n",
       " [2, 8, 75, 16, 24, 6, 11, 10, 17],\n",
       " [2, 8, 75, 16, 24, 6, 11, 10, 17, 28],\n",
       " [1, 29],\n",
       " [1, 29, 76],\n",
       " [1, 29, 76, 16],\n",
       " [1, 29, 76, 16, 4],\n",
       " [1, 29, 76, 16, 4, 30],\n",
       " [1, 29, 76, 16, 4, 30, 3],\n",
       " [1, 29, 76, 16, 4, 30, 3, 18],\n",
       " [1, 29, 76, 16, 4, 30, 3, 18, 19],\n",
       " [2, 13],\n",
       " [2, 13, 14],\n",
       " [2, 13, 14, 9],\n",
       " [2, 13, 14, 9, 77],\n",
       " [2, 13, 14, 9, 77, 38],\n",
       " [2, 13, 14, 9, 77, 38, 3],\n",
       " [2, 13, 14, 9, 77, 38, 3, 7],\n",
       " [1, 78],\n",
       " [1, 78, 79],\n",
       " [1, 78, 79, 80],\n",
       " [1, 78, 79, 80, 81],\n",
       " [1, 78, 79, 80, 81, 5],\n",
       " [1, 78, 79, 80, 81, 5, 82],\n",
       " [1, 78, 79, 80, 81, 5, 82, 83],\n",
       " [1, 78, 79, 80, 81, 5, 82, 83, 41],\n",
       " [1, 78, 79, 80, 81, 5, 82, 83, 41, 84],\n",
       " [2, 8],\n",
       " [2, 8, 42],\n",
       " [2, 8, 42, 4],\n",
       " [2, 8, 42, 4, 85],\n",
       " [2, 8, 42, 4, 85, 86],\n",
       " [2, 8, 42, 4, 85, 86, 87],\n",
       " [2, 8, 42, 4, 85, 86, 87, 3],\n",
       " [2, 8, 42, 4, 85, 86, 87, 3, 30],\n",
       " [2, 8, 42, 4, 85, 86, 87, 3, 30, 18],\n",
       " [2, 8, 42, 4, 85, 86, 87, 3, 30, 18, 19],\n",
       " [1, 18],\n",
       " [1, 18, 88],\n",
       " [1, 18, 88, 20],\n",
       " [1, 18, 88, 20, 89],\n",
       " [1, 18, 88, 20, 89, 90],\n",
       " [1, 18, 88, 20, 89, 90, 91],\n",
       " [1, 18, 88, 20, 89, 90, 91, 18],\n",
       " [1, 18, 88, 20, 89, 90, 91, 18, 12],\n",
       " [1, 18, 88, 20, 89, 90, 91, 18, 12, 92],\n",
       " [1, 18, 88, 20, 89, 90, 91, 18, 12, 92, 18],\n",
       " [2, 43],\n",
       " [2, 43, 44],\n",
       " [2, 43, 44, 33],\n",
       " [2, 43, 44, 33, 6],\n",
       " [2, 43, 44, 33, 6, 93],\n",
       " [2, 43, 44, 33, 6, 93, 3],\n",
       " [2, 43, 44, 33, 6, 93, 3, 17],\n",
       " [2, 43, 44, 33, 6, 93, 3, 17, 19],\n",
       " [2, 43, 44, 33, 6, 93, 3, 17, 19, 94],\n",
       " [1, 95],\n",
       " [1, 95, 96],\n",
       " [1, 95, 96, 3],\n",
       " [1, 95, 96, 3, 45],\n",
       " [1, 95, 96, 3, 45, 25],\n",
       " [1, 95, 96, 3, 45, 25, 19],\n",
       " [2, 8],\n",
       " [2, 8, 46],\n",
       " [2, 8, 46, 26],\n",
       " [2, 8, 46, 26, 47],\n",
       " [2, 8, 46, 26, 47, 11],\n",
       " [2, 8, 46, 26, 47, 11, 3],\n",
       " [2, 8, 46, 26, 47, 11, 3, 27],\n",
       " [2, 8, 46, 26, 47, 11, 3, 27, 4],\n",
       " [2, 8, 46, 26, 47, 11, 3, 27, 4, 21],\n",
       " [1, 97],\n",
       " [1, 97, 46],\n",
       " [1, 97, 46, 6],\n",
       " [1, 97, 46, 6, 48],\n",
       " [1, 97, 46, 6, 48, 11],\n",
       " [1, 97, 46, 6, 48, 11, 3],\n",
       " [1, 97, 46, 6, 48, 11, 3, 98],\n",
       " [1, 97, 46, 6, 48, 11, 3, 98, 99],\n",
       " [2, 13],\n",
       " [2, 13, 14],\n",
       " [2, 13, 14, 9],\n",
       " [2, 13, 14, 9, 100],\n",
       " [2, 13, 14, 9, 100, 101],\n",
       " [2, 13, 14, 9, 100, 101, 10],\n",
       " [2, 13, 14, 9, 100, 101, 10, 4],\n",
       " [2, 13, 14, 9, 100, 101, 10, 4, 7],\n",
       " [2, 13, 14, 9, 100, 101, 10, 4, 7, 15],\n",
       " [2, 13, 14, 9, 100, 101, 10, 4, 7, 15, 21],\n",
       " [1, 34],\n",
       " [1, 34, 35],\n",
       " [1, 34, 35, 20],\n",
       " [1, 34, 35, 20, 102],\n",
       " [1, 34, 35, 20, 102, 24],\n",
       " [1, 34, 35, 20, 102, 24, 49],\n",
       " [1, 34, 35, 20, 102, 24, 49, 5],\n",
       " [1, 34, 35, 20, 102, 24, 49, 5, 103],\n",
       " [2, 8],\n",
       " [2, 8, 6],\n",
       " [2, 8, 6, 4],\n",
       " [2, 8, 6, 4, 104],\n",
       " [2, 8, 6, 4, 104, 50],\n",
       " [2, 8, 6, 4, 104, 50, 3],\n",
       " [2, 8, 6, 4, 104, 50, 3, 15],\n",
       " [1, 1],\n",
       " [1, 1, 105],\n",
       " [1, 1, 105, 16],\n",
       " [1, 1, 105, 16, 51],\n",
       " [1, 1, 105, 16, 51, 106],\n",
       " [1, 1, 105, 16, 51, 106, 107],\n",
       " [1, 1, 105, 16, 51, 106, 107, 108],\n",
       " [1, 1, 105, 16, 51, 106, 107, 108, 37],\n",
       " [1, 1, 105, 16, 51, 106, 107, 108, 37, 7],\n",
       " [1, 1, 105, 16, 51, 106, 107, 108, 37, 7, 109],\n",
       " [2, 43],\n",
       " [2, 43, 110],\n",
       " [2, 43, 110, 6],\n",
       " [2, 43, 110, 6, 48],\n",
       " [2, 43, 110, 6, 48, 11],\n",
       " [2, 43, 110, 6, 48, 11, 32],\n",
       " [2, 43, 110, 6, 48, 11, 32, 111],\n",
       " [2, 43, 110, 6, 48, 11, 32, 111, 4],\n",
       " [2, 43, 110, 6, 48, 11, 32, 111, 4, 112],\n",
       " [2, 43, 110, 6, 48, 11, 32, 111, 4, 112, 52],\n",
       " [1, 53],\n",
       " [1, 53, 113],\n",
       " [1, 53, 113, 114],\n",
       " [1, 53, 113, 114, 5],\n",
       " [1, 53, 113, 114, 5, 115],\n",
       " [1, 53, 113, 114, 5, 115, 116],\n",
       " [2, 13],\n",
       " [2, 13, 14],\n",
       " [2, 13, 14, 9],\n",
       " [2, 13, 14, 9, 117],\n",
       " [2, 13, 14, 9, 117, 25],\n",
       " [2, 13, 14, 9, 117, 25, 118],\n",
       " [2, 13, 14, 9, 117, 25, 118, 10],\n",
       " [2, 13, 14, 9, 117, 25, 118, 10, 4],\n",
       " [2, 13, 14, 9, 117, 25, 118, 10, 4, 54],\n",
       " [1, 55],\n",
       " [1, 55, 22],\n",
       " [1, 55, 22, 35],\n",
       " [1, 55, 22, 35, 20],\n",
       " [1, 55, 22, 35, 20, 119],\n",
       " [1, 55, 22, 35, 20, 119, 120],\n",
       " [1, 55, 22, 35, 20, 119, 120, 12],\n",
       " [1, 55, 22, 35, 20, 119, 120, 12, 25],\n",
       " [1, 55, 22, 35, 20, 119, 120, 12, 25, 121],\n",
       " [2, 8],\n",
       " [2, 8, 6],\n",
       " [2, 8, 6, 122],\n",
       " [2, 8, 6, 122, 123],\n",
       " [2, 8, 6, 122, 123, 5],\n",
       " [2, 8, 6, 122, 123, 5, 39],\n",
       " [2, 8, 6, 122, 123, 5, 39, 6],\n",
       " [2, 8, 6, 122, 123, 5, 39, 6, 36],\n",
       " [2, 8, 6, 122, 123, 5, 39, 6, 36, 56],\n",
       " [2, 8, 6, 122, 123, 5, 39, 6, 36, 56, 124],\n",
       " [1, 125],\n",
       " [1, 125, 126],\n",
       " [1, 125, 126, 57],\n",
       " [1, 125, 126, 57, 7],\n",
       " [1, 125, 126, 57, 7, 127],\n",
       " [1, 125, 126, 57, 7, 127, 20],\n",
       " [1, 125, 126, 57, 7, 127, 20, 128],\n",
       " [1, 125, 126, 57, 7, 127, 20, 128, 32],\n",
       " [1, 125, 126, 57, 7, 127, 20, 128, 32, 129],\n",
       " [1, 125, 126, 57, 7, 127, 20, 128, 32, 129, 130],\n",
       " [1, 125, 126, 57, 7, 127, 20, 128, 32, 129, 130, 51],\n",
       " [1, 125, 126, 57, 7, 127, 20, 128, 32, 129, 130, 51, 5],\n",
       " [1, 125, 126, 57, 7, 127, 20, 128, 32, 129, 130, 51, 5, 131],\n",
       " [1, 125, 126, 57, 7, 127, 20, 128, 32, 129, 130, 51, 5, 131, 27],\n",
       " [1, 125, 126, 57, 7, 127, 20, 128, 32, 129, 130, 51, 5, 131, 27, 23],\n",
       " [2, 26],\n",
       " [2, 26, 17],\n",
       " [2, 26, 17, 21],\n",
       " [2, 26, 17, 21, 132],\n",
       " [2, 26, 17, 21, 132, 3],\n",
       " [2, 26, 17, 21, 132, 3, 58],\n",
       " [2, 26, 17, 21, 132, 3, 58, 23],\n",
       " [2, 26, 17, 21, 132, 3, 58, 23, 133],\n",
       " [1, 134],\n",
       " [1, 134, 31],\n",
       " [1, 134, 31, 135],\n",
       " [1, 134, 31, 135, 36],\n",
       " [1, 134, 31, 135, 36, 26],\n",
       " [1, 134, 31, 135, 36, 26, 47],\n",
       " [1, 134, 31, 135, 36, 26, 47, 136],\n",
       " [1, 134, 31, 135, 36, 26, 47, 136, 3],\n",
       " [1, 134, 31, 135, 36, 26, 47, 136, 3, 58],\n",
       " [1, 134, 31, 135, 36, 26, 47, 136, 3, 58, 23],\n",
       " [1, 134, 31, 135, 36, 26, 47, 136, 3, 58, 23, 137],\n",
       " [2, 8],\n",
       " [2, 8, 59],\n",
       " [2, 8, 59, 33],\n",
       " [2, 8, 59, 33, 6],\n",
       " [2, 8, 59, 33, 6, 11],\n",
       " [2, 8, 59, 33, 6, 11, 10],\n",
       " [2, 8, 59, 33, 6, 11, 10, 4],\n",
       " [2, 8, 59, 33, 6, 11, 10, 4, 138],\n",
       " [2, 8, 59, 33, 6, 11, 10, 4, 138, 60],\n",
       " [2, 8, 59, 33, 6, 11, 10, 4, 138, 60, 3],\n",
       " [2, 8, 59, 33, 6, 11, 10, 4, 138, 60, 3, 45],\n",
       " [2, 8, 59, 33, 6, 11, 10, 4, 138, 60, 3, 45, 25],\n",
       " [2, 8, 59, 33, 6, 11, 10, 4, 138, 60, 3, 45, 25, 19],\n",
       " [1, 139],\n",
       " [1, 139, 59],\n",
       " [1, 139, 59, 33],\n",
       " [2, 8],\n",
       " [2, 8, 6],\n",
       " [2, 8, 6, 4],\n",
       " [2, 8, 6, 4, 140],\n",
       " [2, 8, 6, 4, 140, 16],\n",
       " [2, 8, 6, 4, 140, 16, 141],\n",
       " [2, 8, 6, 4, 140, 16, 141, 142],\n",
       " [2, 8, 6, 4, 140, 16, 141, 142, 10],\n",
       " [2, 8, 6, 4, 140, 16, 141, 142, 10, 7],\n",
       " [1, 36],\n",
       " [1, 36, 143],\n",
       " [1, 36, 143, 5],\n",
       " [1, 36, 143, 5, 144],\n",
       " [1, 36, 143, 5, 144, 145],\n",
       " [1, 36, 143, 5, 144, 145, 27],\n",
       " [1, 36, 143, 5, 144, 145, 27, 55],\n",
       " [1, 36, 143, 5, 144, 145, 27, 55, 146],\n",
       " [1, 36, 143, 5, 144, 145, 27, 55, 146, 60],\n",
       " [1, 36, 143, 5, 144, 145, 27, 55, 146, 60, 147],\n",
       " [2, 8],\n",
       " [2, 8, 148],\n",
       " [2, 8, 148, 26],\n",
       " [2, 8, 148, 26, 9],\n",
       " [2, 8, 148, 26, 9, 34],\n",
       " [2, 8, 148, 26, 9, 34, 3],\n",
       " [2, 8, 148, 26, 9, 34, 3, 149],\n",
       " [2, 8, 148, 26, 9, 34, 3, 149, 7],\n",
       " [2, 8, 148, 26, 9, 34, 3, 149, 7, 5],\n",
       " [2, 8, 148, 26, 9, 34, 3, 149, 7, 5, 15],\n",
       " [1, 150],\n",
       " [1, 150, 20],\n",
       " [1, 150, 20, 151],\n",
       " [1, 150, 20, 151, 12],\n",
       " [1, 150, 20, 151, 12, 152],\n",
       " [2, 13],\n",
       " [2, 13, 14],\n",
       " [2, 13, 14, 9],\n",
       " [2, 13, 14, 9, 153],\n",
       " [2, 13, 14, 9, 153, 4],\n",
       " [2, 13, 14, 9, 153, 4, 54],\n",
       " [1, 41],\n",
       " [1, 41, 27],\n",
       " [1, 41, 27, 154],\n",
       " [1, 41, 27, 154, 5],\n",
       " [1, 41, 27, 154, 5, 155],\n",
       " [1, 41, 27, 154, 5, 155, 156],\n",
       " [1, 41, 27, 154, 5, 155, 156, 157],\n",
       " [1, 41, 27, 154, 5, 155, 156, 157, 10],\n",
       " [1, 41, 27, 154, 5, 155, 156, 157, 10, 1],\n",
       " [1, 41, 27, 154, 5, 155, 156, 157, 10, 1, 158],\n",
       " [1, 41, 27, 154, 5, 155, 156, 157, 10, 1, 158, 61],\n",
       " [1, 41, 27, 154, 5, 155, 156, 157, 10, 1, 158, 61, 61],\n",
       " [1, 41, 27, 154, 5, 155, 156, 157, 10, 1, 158, 61, 61, 159],\n",
       " [2, 13],\n",
       " [2, 13, 14],\n",
       " [2, 13, 14, 9],\n",
       " [2, 13, 14, 9, 160],\n",
       " [2, 13, 14, 9, 160, 4],\n",
       " [2, 13, 14, 9, 160, 4, 161],\n",
       " [2, 13, 14, 9, 160, 4, 161, 52],\n",
       " [1, 22],\n",
       " [1, 22, 162],\n",
       " [1, 22, 162, 163],\n",
       " [1, 22, 162, 163, 53],\n",
       " [1, 22, 162, 163, 53, 44],\n",
       " [1, 22, 162, 163, 53, 44, 164],\n",
       " [1, 22, 162, 163, 53, 44, 164, 5],\n",
       " [1, 22, 162, 163, 53, 44, 164, 5, 165],\n",
       " [1, 22, 162, 163, 53, 44, 164, 5, 165, 166],\n",
       " [2, 8],\n",
       " [2, 8, 24],\n",
       " [2, 8, 24, 49],\n",
       " [2, 8, 24, 49, 35],\n",
       " [2, 8, 24, 49, 35, 42],\n",
       " [2, 8, 24, 49, 35, 42, 56],\n",
       " [2, 8, 24, 49, 35, 42, 56, 3],\n",
       " [2, 8, 24, 49, 35, 42, 56, 3, 17],\n",
       " [2, 8, 24, 49, 35, 42, 56, 3, 17, 28],\n",
       " [1, 167],\n",
       " [1, 167, 168],\n",
       " [1, 167, 168, 169],\n",
       " [1, 167, 168, 169, 5],\n",
       " [1, 167, 168, 169, 5, 170],\n",
       " [2, 13],\n",
       " [2, 13, 14],\n",
       " [2, 13, 14, 9],\n",
       " [2, 13, 14, 9, 62],\n",
       " [2, 13, 14, 9, 62, 4],\n",
       " [2, 13, 14, 9, 62, 4, 57],\n",
       " [2, 13, 14, 9, 62, 4, 57, 21],\n",
       " [1, 62],\n",
       " [1, 62, 4],\n",
       " [1, 62, 4, 21],\n",
       " [1, 62, 4, 21, 22],\n",
       " [1, 62, 4, 21, 22, 171],\n",
       " [1, 62, 4, 21, 22, 171, 12],\n",
       " [1, 62, 4, 21, 22, 171, 12, 172],\n",
       " [1, 62, 4, 21, 22, 171, 12, 172, 50],\n",
       " [1, 62, 4, 21, 22, 171, 12, 172, 50, 3],\n",
       " [1, 62, 4, 21, 22, 171, 12, 172, 50, 3, 173],\n",
       " [1, 62, 4, 21, 22, 171, 12, 172, 50, 3, 173, 34]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f2c8547-603f-4642-9ad1-ce87d773aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e20d159-5b33-479b-914f-9bc233c59e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences,maxlen=max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fce622d-d4d7-439e-b379-a404a3a13d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   7,   5],\n",
       "       [  0,   0,   0, ...,   7,   5,  15],\n",
       "       [  0,   0,   0, ...,   0,   2,   8],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 172,  50,   3],\n",
       "       [  0,   0,   0, ...,  50,   3, 173],\n",
       "       [  0,   0,   0, ...,   3, 173,  34]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82d35610-23ec-4e78-b897-3172ddd4a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_input_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88fcb869-a2a8-44e9-8916-bd2e73691d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12c3df7b-bfdd-4537-a381-ef7cad4db676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,  15,   8,   6,   4,  63,  16,  22,   7,  10,  17,  28,   7,\n",
       "         6,  11,   3,  64,  65,  37,  29,  30,  38,  39,  66,   9,  67,\n",
       "        15,  31,   7,  32,  68,  69,  12,  40,  70,  71,  72,  31,  40,\n",
       "        29,  73,  12,  23,  74,  24,   8,  75,  16,  24,   6,  11,  10,\n",
       "        17,  28,  29,  76,  16,   4,  30,   3,  18,  19,  13,  14,   9,\n",
       "        77,  38,   3,   7,  78,  79,  80,  81,   5,  82,  83,  41,  84,\n",
       "         8,  42,   4,  85,  86,  87,   3,  30,  18,  19,  18,  88,  20,\n",
       "        89,  90,  91,  18,  12,  92,  18,  43,  44,  33,   6,  93,   3,\n",
       "        17,  19,  94,  95,  96,   3,  45,  25,  19,   8,  46,  26,  47,\n",
       "        11,   3,  27,   4,  21,  97,  46,   6,  48,  11,   3,  98,  99,\n",
       "        13,  14,   9, 100, 101,  10,   4,   7,  15,  21,  34,  35,  20,\n",
       "       102,  24,  49,   5, 103,   8,   6,   4, 104,  50,   3,  15,   1,\n",
       "       105,  16,  51, 106, 107, 108,  37,   7, 109,  43, 110,   6,  48,\n",
       "        11,  32, 111,   4, 112,  52,  53, 113, 114,   5, 115, 116,  13,\n",
       "        14,   9, 117,  25, 118,  10,   4,  54,  55,  22,  35,  20, 119,\n",
       "       120,  12,  25, 121,   8,   6, 122, 123,   5,  39,   6,  36,  56,\n",
       "       124, 125, 126,  57,   7, 127,  20, 128,  32, 129, 130,  51,   5,\n",
       "       131,  27,  23,  26,  17,  21, 132,   3,  58,  23, 133, 134,  31,\n",
       "       135,  36,  26,  47, 136,   3,  58,  23, 137,   8,  59,  33,   6,\n",
       "        11,  10,   4, 138,  60,   3,  45,  25,  19, 139,  59,  33,   8,\n",
       "         6,   4, 140,  16, 141, 142,  10,   7,  36, 143,   5, 144, 145,\n",
       "        27,  55, 146,  60, 147,   8, 148,  26,   9,  34,   3, 149,   7,\n",
       "         5,  15, 150,  20, 151,  12, 152,  13,  14,   9, 153,   4,  54,\n",
       "        41,  27, 154,   5, 155, 156, 157,  10,   1, 158,  61,  61, 159,\n",
       "        13,  14,   9, 160,   4, 161,  52,  22, 162, 163,  53,  44, 164,\n",
       "         5, 165, 166,   8,  24,  49,  35,  42,  56,   3,  17,  28, 167,\n",
       "       168, 169,   5, 170,  13,  14,   9,  62,   4,  57,  21,  62,   4,\n",
       "        21,  22, 171,  12, 172,  50,   3, 173,  34])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f4f6ccb-8ff1-481f-815e-7ae5e98c6e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 16)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79a774f7-8cc7-48db-a6e0-0ba9a6478653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b87f14d-0f24-4181-bdd9-a789cdbebd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y=to_categorical(Y,num_classes=174)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a228d8d9-c2e1-4e78-b350-01010228d030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c298ffca-8f46-4b13-ab52-c1c27e4375b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f56ccf57-8402-4e50-a79b-f7c42b8bf6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(174,100,input_length=30))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(174,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e5980d7a-433d-488c-9b89-b9a3915a0a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "95306425-8a72-4592-b223-a2b23a523443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5aba49bf-7c28-4a9b-8bd8-64dbedc2cc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8756 - loss: 0.4183\n",
      "Epoch 2/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8811 - loss: 0.3928\n",
      "Epoch 3/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8775 - loss: 0.4126\n",
      "Epoch 4/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8733 - loss: 0.3823\n",
      "Epoch 5/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8779 - loss: 0.3936\n",
      "Epoch 6/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8706 - loss: 0.4000\n",
      "Epoch 7/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8858 - loss: 0.3648\n",
      "Epoch 8/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8637 - loss: 0.4002\n",
      "Epoch 9/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8918 - loss: 0.3882\n",
      "Epoch 10/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8609 - loss: 0.4547\n",
      "Epoch 11/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8853 - loss: 0.3836\n",
      "Epoch 12/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8602 - loss: 0.4136\n",
      "Epoch 13/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8796 - loss: 0.3863\n",
      "Epoch 14/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8839 - loss: 0.3926\n",
      "Epoch 15/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8651 - loss: 0.4176\n",
      "Epoch 16/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8774 - loss: 0.3942\n",
      "Epoch 17/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8853 - loss: 0.3947\n",
      "Epoch 18/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8867 - loss: 0.3684\n",
      "Epoch 19/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8807 - loss: 0.3705\n",
      "Epoch 20/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8665 - loss: 0.3963\n",
      "Epoch 21/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8926 - loss: 0.3552\n",
      "Epoch 22/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8669 - loss: 0.4085\n",
      "Epoch 23/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8695 - loss: 0.3890\n",
      "Epoch 24/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8654 - loss: 0.3913\n",
      "Epoch 25/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8867 - loss: 0.3386\n",
      "Epoch 26/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9005 - loss: 0.3345\n",
      "Epoch 27/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8803 - loss: 0.3523\n",
      "Epoch 28/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8678 - loss: 0.3847\n",
      "Epoch 29/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8548 - loss: 0.4172\n",
      "Epoch 30/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8712 - loss: 0.3847\n",
      "Epoch 31/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8792 - loss: 0.3489\n",
      "Epoch 32/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8710 - loss: 0.3926\n",
      "Epoch 33/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8939 - loss: 0.3639\n",
      "Epoch 34/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8916 - loss: 0.3578\n",
      "Epoch 35/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8766 - loss: 0.4086\n",
      "Epoch 36/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8716 - loss: 0.3605\n",
      "Epoch 37/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8857 - loss: 0.3568\n",
      "Epoch 38/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8561 - loss: 0.4005\n",
      "Epoch 39/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8787 - loss: 0.3426\n",
      "Epoch 40/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8741 - loss: 0.3550\n",
      "Epoch 41/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9019 - loss: 0.3209\n",
      "Epoch 42/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9152 - loss: 0.2785\n",
      "Epoch 43/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8740 - loss: 0.3598\n",
      "Epoch 44/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8686 - loss: 0.4017\n",
      "Epoch 45/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8716 - loss: 0.3979\n",
      "Epoch 46/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8680 - loss: 0.3721\n",
      "Epoch 47/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8814 - loss: 0.3428\n",
      "Epoch 48/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8735 - loss: 0.3823\n",
      "Epoch 49/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8728 - loss: 0.3725\n",
      "Epoch 50/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8784 - loss: 0.3531\n",
      "Epoch 51/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8685 - loss: 0.3781\n",
      "Epoch 52/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8856 - loss: 0.3265\n",
      "Epoch 53/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8685 - loss: 0.4136\n",
      "Epoch 54/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8540 - loss: 0.3931\n",
      "Epoch 55/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8572 - loss: 0.4142\n",
      "Epoch 56/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8855 - loss: 0.3533\n",
      "Epoch 57/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9098 - loss: 0.3145\n",
      "Epoch 58/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8789 - loss: 0.3792\n",
      "Epoch 59/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8821 - loss: 0.3438\n",
      "Epoch 60/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8735 - loss: 0.3771\n",
      "Epoch 61/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8869 - loss: 0.3508\n",
      "Epoch 62/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8703 - loss: 0.3432\n",
      "Epoch 63/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8861 - loss: 0.3549\n",
      "Epoch 64/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8756 - loss: 0.3802\n",
      "Epoch 65/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8852 - loss: 0.3179\n",
      "Epoch 66/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8620 - loss: 0.3897\n",
      "Epoch 67/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8600 - loss: 0.3936\n",
      "Epoch 68/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8741 - loss: 0.3542\n",
      "Epoch 69/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8995 - loss: 0.3022\n",
      "Epoch 70/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8710 - loss: 0.3765\n",
      "Epoch 71/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8666 - loss: 0.3881\n",
      "Epoch 72/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8556 - loss: 0.4293\n",
      "Epoch 73/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8833 - loss: 0.3266\n",
      "Epoch 74/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8847 - loss: 0.3295\n",
      "Epoch 75/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8788 - loss: 0.3260\n",
      "Epoch 76/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9075 - loss: 0.2853\n",
      "Epoch 77/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8563 - loss: 0.3918\n",
      "Epoch 78/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8923 - loss: 0.3411\n",
      "Epoch 79/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8772 - loss: 0.3462\n",
      "Epoch 80/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8729 - loss: 0.3599\n",
      "Epoch 81/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8727 - loss: 0.3478\n",
      "Epoch 82/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8634 - loss: 0.3598\n",
      "Epoch 83/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8692 - loss: 0.3798\n",
      "Epoch 84/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8897 - loss: 0.3415\n",
      "Epoch 85/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8689 - loss: 0.3436\n",
      "Epoch 86/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8738 - loss: 0.3540\n",
      "Epoch 87/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8683 - loss: 0.3776\n",
      "Epoch 88/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8668 - loss: 0.3855\n",
      "Epoch 89/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8915 - loss: 0.3218\n",
      "Epoch 90/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8840 - loss: 0.3253\n",
      "Epoch 91/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8676 - loss: 0.3828\n",
      "Epoch 92/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8775 - loss: 0.3211\n",
      "Epoch 93/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8673 - loss: 0.3569\n",
      "Epoch 94/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8722 - loss: 0.3634\n",
      "Epoch 95/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8789 - loss: 0.3674\n",
      "Epoch 96/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8584 - loss: 0.3762\n",
      "Epoch 97/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8586 - loss: 0.3870\n",
      "Epoch 98/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8775 - loss: 0.3661\n",
      "Epoch 99/99\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8473 - loss: 0.3849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e1b4153e50>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d96662f2-1eba-45f1-8317-42f4372b81e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      " CNN is used for feature extraction from is\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      " CNN is used for feature extraction from is used\n"
     ]
    }
   ],
   "source": [
    "text=\" CNN is used for feature extraction from\"\n",
    "for i in range(2):\n",
    "   token_text=tokenizer.texts_to_sequences([text])[0]\n",
    "   padded_token_text =pad_sequences([token_text],maxlen=56,padding='pre')\n",
    "   pos =np.argmax(model.predict(padded_token_text))\n",
    "   for word,index in tokenizer.word_index.items():\n",
    "      if index==pos:\n",
    "         text = text+\" \" + word\n",
    "         print(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "98f13d99-09e4-4183-9562-8442ee513506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f9d816d-b879-41a5-9f29-f2f59b3f4e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'q': 2,\n",
       " 'for': 3,\n",
       " 'the': 4,\n",
       " 'and': 5,\n",
       " 'is': 6,\n",
       " 'cnn': 7,\n",
       " 'what': 8,\n",
       " 'you': 9,\n",
       " 'in': 10,\n",
       " 'used': 11,\n",
       " 'or': 12,\n",
       " 'how': 13,\n",
       " 'do': 14,\n",
       " 'lstm': 15,\n",
       " 'of': 16,\n",
       " 'this': 17,\n",
       " 'tumor': 18,\n",
       " 'classification': 19,\n",
       " 'like': 20,\n",
       " 'model': 21,\n",
       " 'using': 22,\n",
       " 'time': 23,\n",
       " 'data': 24,\n",
       " 'class': 25,\n",
       " 'can': 26,\n",
       " 'training': 27,\n",
       " 'project': 28,\n",
       " 'mri': 29,\n",
       " 'brain': 30,\n",
       " 'with': 31,\n",
       " 'to': 32,\n",
       " 'function': 33,\n",
       " 'use': 34,\n",
       " 'techniques': 35,\n",
       " 'it': 36,\n",
       " 'from': 37,\n",
       " 'images': 38,\n",
       " 'why': 39,\n",
       " 'sequential': 40,\n",
       " 'into': 41,\n",
       " 'are': 42,\n",
       " 'which': 43,\n",
       " 'loss': 44,\n",
       " 'multi': 45,\n",
       " 'optimizer': 46,\n",
       " 'be': 47,\n",
       " 'commonly': 48,\n",
       " 'augmentation': 49,\n",
       " 'format': 50,\n",
       " 'features': 51,\n",
       " 'performance': 52,\n",
       " 'accuracy': 53,\n",
       " 'dataset': 54,\n",
       " 'by': 55,\n",
       " 'useful': 56,\n",
       " 'trained': 57,\n",
       " 'real': 58,\n",
       " 'activation': 59,\n",
       " 'layer': 60,\n",
       " '15': 61,\n",
       " 'save': 62,\n",
       " 'purpose': 63,\n",
       " 'feature': 64,\n",
       " 'extraction': 65,\n",
       " 'might': 66,\n",
       " 'integrate': 67,\n",
       " 'capture': 68,\n",
       " 'temporal': 69,\n",
       " 'patterns': 70,\n",
       " 'if': 71,\n",
       " 'dealing': 72,\n",
       " 'slices': 73,\n",
       " 'series': 74,\n",
       " 'type': 75,\n",
       " 'scans': 76,\n",
       " 'preprocess': 77,\n",
       " 'resize': 78,\n",
       " 'normalize': 79,\n",
       " 'pixel': 80,\n",
       " 'values': 81,\n",
       " 'convert': 82,\n",
       " 'them': 83,\n",
       " 'tensors': 84,\n",
       " 'common': 85,\n",
       " 'output': 86,\n",
       " 'classes': 87,\n",
       " 'types': 88,\n",
       " 'glioma': 89,\n",
       " 'meningioma': 90,\n",
       " 'pituitary': 91,\n",
       " 'no': 92,\n",
       " 'suitable': 93,\n",
       " 'task': 94,\n",
       " 'categorical': 95,\n",
       " 'crossentropy': 96,\n",
       " 'adam': 97,\n",
       " 'its': 98,\n",
       " 'efficiency': 99,\n",
       " 'avoid': 100,\n",
       " 'overfitting': 101,\n",
       " 'dropout': 102,\n",
       " 'regularization': 103,\n",
       " 'input': 104,\n",
       " 'sequence': 105,\n",
       " 'e': 106,\n",
       " 'g': 107,\n",
       " 'extracted': 108,\n",
       " 'layers': 109,\n",
       " 'metric': 110,\n",
       " 'evaluate': 111,\n",
       " \"model's\": 112,\n",
       " 'precision': 113,\n",
       " 'recall': 114,\n",
       " 'f1': 115,\n",
       " 'score': 116,\n",
       " 'handle': 117,\n",
       " 'imbalance': 118,\n",
       " 'oversampling': 119,\n",
       " 'undersampling': 120,\n",
       " 'weights': 121,\n",
       " 'transfer': 122,\n",
       " 'learning': 123,\n",
       " 'here': 124,\n",
       " 'reusing': 125,\n",
       " 'pre': 126,\n",
       " 'models': 127,\n",
       " 'vgg16': 128,\n",
       " 'leverage': 129,\n",
       " 'learned': 130,\n",
       " 'reduce': 131,\n",
       " 'work': 132,\n",
       " 'detection': 133,\n",
       " 'yes': 134,\n",
       " 'optimizations': 135,\n",
       " 'adapted': 136,\n",
       " 'applications': 137,\n",
       " 'final': 138,\n",
       " 'softmax': 139,\n",
       " 'role': 140,\n",
       " 'batch': 141,\n",
       " 'normalization': 142,\n",
       " 'stabilizes': 143,\n",
       " 'speeds': 144,\n",
       " 'up': 145,\n",
       " 'normalizing': 146,\n",
       " 'inputs': 147,\n",
       " 'library': 148,\n",
       " 'implementing': 149,\n",
       " 'libraries': 150,\n",
       " 'tensorflow': 151,\n",
       " 'pytorch': 152,\n",
       " 'split': 153,\n",
       " 'validation': 154,\n",
       " 'testing': 155,\n",
       " 'sets': 156,\n",
       " 'typically': 157,\n",
       " '70': 158,\n",
       " 'ratio': 159,\n",
       " 'visualize': 160,\n",
       " 'model’s': 161,\n",
       " 'confusion': 162,\n",
       " 'matrices': 163,\n",
       " 'plots': 164,\n",
       " 'roc': 165,\n",
       " 'curves': 166,\n",
       " 'rotation': 167,\n",
       " 'flipping': 168,\n",
       " 'zooming': 169,\n",
       " 'shifting': 170,\n",
       " 'h5': 171,\n",
       " 'pth': 172,\n",
       " 'future': 173}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "76652bdd-4a75-4c5b-ba53-e4d2f5907530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overfitting\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197f1c3-cf21-4996-b595-9053b323ec53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
